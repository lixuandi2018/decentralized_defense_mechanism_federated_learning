**Author:** Vivek Khimani
**Contact:** +12673049080
**Purpose:** Interaction with CollectUpdatesContract (Federated Learning Research Paper)
-------

##INSTALLATIONS REQUIRED: 
-	web3 - "pip install web3"
-	ipfs-api - "pip install ipfs-api"
-	local ipfs installation - "https://docs.ipfs.io/guides/guides/install/"



2) FILES INFORMATION:
	a) my_abi.json => abi of the contract stored in json format (VIVEK)
	b) credentials.py => formatted abi and bytecode (VIVEK)
	c) DeployContract.py => used to store and create contract instance (VIVEK)
	d) all_clienty.py => hash map (dictionary) containing address and private key of all clients (VIVEK & ABHISHEK)
	e) whitelisted.py => NEED TO BE GENERATED BY ABHISHEK using some AGENT SAMPLING MECHANISM. data structure is explained in the file. (ABHISHEK)
	f) main.py => calling interface for smart contract methods. FIND more details in INSTRUCTIONS section. (VIVEK & ABHISHEK) 
	g) ipfs_conn.py => USED to establish connection with IPFS api and add the local updates to IPFS API and generate hashes.(VIVEK & ABHISHEK)



3) INSTRUCTIONS:
	a) Data for all the agents can be found in "all_clients.py" in a hashMap structure which is explained in the file. 
	b) ABHISHEK needs to add REPUTATION SCORE data to the hashMap (if required).
	c) ABHISHEK needs to run an AGENT SAMPLING SCRIPT on "all_clients.py" that will sample whitelisted agents and put it in a data structure explained in "whitelisted.py".
	d) Once the whitelisted agents are available (in the given format), ABHISHEK needs to run the script XXXX.py. This will add the whitelisted agents to blockchain.

	**** IPFS DAEMON has to be activated at this stage on the local computer using IPFS-CLI. Please find it online. Should be straightforward. ****

	e) Later, ABHISHEK can run "ipfs_conn.py" which will serialize the local updates from each agent and add it to the IPFS, generate hashes, and store those hashes on the blockchain. 
	f) At the end, there will be a HASHMAP (mapping) stored on the blockchain which will contain the AGENT ADDRESSES as the key, and the IPFS HASHES generated for their data as a VALUE. 
	g) The data structure can be used to query and use the data for further hypersphere-based classification model. 
